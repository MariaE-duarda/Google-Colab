import requests
from bs4 import BeautifulSoup
import csv

# Define the URL to scrape
url = "https://www.americanas.com.br/categoria/livros"

# Create a new CSV file to write the data
with open("americanas_data.csv", "w", newline="") as csvfile:
    fieldnames = ["title", "price", "rating", "url"]
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()

    while url:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")

        products = soup.find_all("li", {"class": "nm-product-card"})

        for product in products:
            title = product.find("span", {"class": "title"}).text
            price = product.find("span", {"class":"price__SalesPrice"}).text
            rating = product.find("span", {"class":"rating__AvgRating"}).text
            link = product.find("a", {"class":"card__image-link"})["href"]
            writer.writerow({"title": title, "price": price, "rating": rating, "url": link})

        next_page = soup.find("li", {"class":"next"})
        if next_page:
            url = "https://www.americanas.com.br" + next_page.find("a")["href"]
        else:
            url = None
